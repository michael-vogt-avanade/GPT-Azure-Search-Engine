{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Queries with and without Azure OpenAI"
      ],
      "metadata": {},
      "id": "d59d527f-1100-45ff-b051-5f7c9029d94d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our Search Engine loaded **from two different data sources in two diferent indexes**, we are going to try some example queries and then use Azure OpenAI service to see if we can get even better results.\n",
        "\n",
        "The idea is that a user can ask a question about Computer Science (first datasource/index) or about Covid (second datasource/index), and the engine will respond accordingly.\n",
        "This **Multi-Index** demo, mimics the scenario where a company loads multiple type of documents of different types and about completly different topics and the search engine must respond with the most relevant results."
      ],
      "metadata": {},
      "id": "eb9a9444-dc90-4fc3-aea7-8ee918301aba"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up variables"
      ],
      "metadata": {},
      "id": "71f6c7e3-9037-4b1e-ae17-1deaa27b9c08"
    },
    {
      "cell_type": "code",
      "source": [
        "# 2023Apr20 mikes copy of the workshop notebooks...\n",
        "# NOTE - BEFORE this notebook can be executed, the computer instance MUST have had pip install requirements executed, so the langChain packages install.....\n",
        "import os\n",
        "import urllib\n",
        "import requests\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "from IPython.display import display, HTML\n",
        "from langchain.llms import AzureOpenAI\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "from app.embeddings import OpenAIEmbeddings\n",
        "from app.prompts import STUFF_PROMPT, REFINE_PROMPT, REFINE_QUESTION_PROMPT\n",
        "\n",
        "# Don't mess with this unless you really know what you are doing\n",
        "AZURE_SEARCH_API_VERSION = '2021-04-30-Preview'\n",
        "AZURE_OPENAI_API_VERSION = \"2023-03-15-preview\"   # NOTE this causes trouble\n",
        "\n",
        "# Change these below with your own services credentials\n",
        "#AZURE_SEARCH_ENDPOINT = \"Enter your Azure Cognitive Search Endpoint ...\"\n",
        "AZURE_SEARCH_ENDPOINT = \"https://azure-cog-search-hw3sksxnht5m6.search.windows.net\"\n",
        "\n",
        "#AZURE_SEARCH_KEY = \"Enter your Azure Cognitive Search Key ...\"\n",
        "AZURE_SEARCH_KEY = \"ujyMyQ6sOIPDeTghq3cKIOP8J2liyrNSVqSn0CKMU0AzSeCisufr\"\n",
        "\n",
        "#AZURE_OPENAI_ENDPOINT = \"Enter your Azure OpenAI Endpoint ...\"\n",
        "AZURE_OPENAI_ENDPOINT = \"https://aoai-exerciseresource-01.openai.azure.com/\"\n",
        "\n",
        "#AZURE_OPENAI_API_KEY = \"Enter your Azure OpenAI Key ...\"\n",
        "AZURE_OPENAI_API_KEY = \"21f30f0fa43b4027b3179dd340eb9523\""
      ],
      "outputs": [],
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1682295734634
        }
      },
      "id": "8e50b404-a061-49e7-a3c7-c6eabc98ff0f"
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the Payloads header\n",
        "headers = {'Content-Type': 'application/json','api-key': AZURE_SEARCH_KEY}"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1682294366476
        }
      },
      "id": "2f2c22f8-79ab-405c-95e8-77a1978e53bc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Index Search queries"
      ],
      "metadata": {},
      "id": "9297d29b-1f61-4dce-858e-bf4272172dba"
    },
    {
      "cell_type": "code",
      "source": [
        "# Index that we are going to query (from Notebook 01 and 02)\n",
        "index1_name = \"cogsrch-index-files\"\n",
        "index2_name = \"cogsrch-index-csv\"\n",
        "indexes = [index1_name, index2_name]"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1682294375833
        },
        "scrolled": true,
        "tags": []
      },
      "id": "5a46e2d3-298a-4708-83de-9e108b1a117a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try questions that you think might be answered or addressed in computer science papers in 2020-2021 or that can be addressed by medical publications about COVID in 2020. Try comparing the results with the open version of ChatGPT.<br>\n",
        "The idea is that the answers using Azure OpenAI only looks at the information contained on these publications.\n",
        "\n",
        "**Example Questions you can ask**:\n",
        "- What is CLP?\n",
        "- How Markov chains work?\n",
        "- What are some examples of reinforcement learning?\n",
        "- What are the main risk factors for Covid-19?\n",
        "- What medicine reduces inflamation in the lungs?\n",
        "- Why Covid doesn't affect kids that much compared to adults?\n",
        "- Does chloroquine really works against covid?\n",
        "- tell me Use cases where I can use deep learning to solve it"
      ],
      "metadata": {},
      "id": "1c62ebb2-d7be-4bfb-b1ba-4db86c11839a"
    },
    {
      "cell_type": "code",
      "source": [
        "#QUESTION = \"What is CLP?\" \n",
        "QUESTION = \"What is CDP?\" # answer mike is looking for is related to Client Data Protection\n",
        "# This questions is interesting since CLP means something in Computer science and means something different in medical field "
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1682294490589
        }
      },
      "id": "b9b53c14-19bd-451f-aa43-7ad27ccfeead"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Search on both indexes individually and aggragate results\n",
        "\n",
        "Note: In order to standarize the indexes we are setting 4 mandatory fields to be present on each index: id, title, content, pages, language. These fields must be present in each index so that each document can be treated the same along the code."
      ],
      "metadata": {},
      "id": "f6d925eb-7f9c-429e-a62a-4c37d7702caf"
    },
    {
      "cell_type": "code",
      "source": [
        "# MIKE - at first errored, mike had created the NEW Cog Search Resource but did NOT set the Semantic Search Availability to Either FREE or STANDARD <- it was UNset, and so caused error....\n",
        "agg_search_results = []\n",
        "\n",
        "for index in indexes:\n",
        "    url = AZURE_SEARCH_ENDPOINT + '/indexes/'+ index + '/docs'\n",
        "    url += '?api-version={}'.format(AZURE_SEARCH_API_VERSION)\n",
        "    url += '&search={}'.format(QUESTION)\n",
        "    url += '&select=*'\n",
        "#    url += '&$top=10'  # You can change this to anything you need/want\n",
        "    url += '&$top=3'  # You can change this to anything you need/want\n",
        "    url += '&queryLanguage=en-us'\n",
        "    url += '&queryType=semantic'\n",
        "    url += '&semanticConfiguration=my-semantic-config'\n",
        "    url += '&$count=true'\n",
        "    url += '&speller=lexicon'\n",
        "    url += '&answers=extractive|count-3'\n",
        "    url += '&captions=extractive|highlight-false'\n",
        "\n",
        "    resp = requests.get(url, headers=headers)\n",
        "    print(url)\n",
        "    print(resp.status_code)\n",
        "\n",
        "    search_results = resp.json()\n",
        "    agg_search_results.append(search_results)\n",
        "    print(\"Results Found: {}, Results Returned: {}\".format(search_results['@odata.count'], len(search_results['value'])))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "https://azure-cog-search-hw3sksxnht5m6.search.windows.net/indexes/cogsrch-index-files/docs?api-version=2021-04-30-Preview&search=What is CDP?&select=*&$top=3&queryLanguage=en-us&queryType=semantic&semanticConfiguration=my-semantic-config&$count=true&speller=lexicon&answers=extractive|count-3&captions=extractive|highlight-false\n200\nResults Found: 10, Results Returned: 3\nhttps://azure-cog-search-hw3sksxnht5m6.search.windows.net/indexes/cogsrch-index-csv/docs?api-version=2021-04-30-Preview&search=What is CDP?&select=*&$top=3&queryLanguage=en-us&queryType=semantic&semanticConfiguration=my-semantic-config&$count=true&speller=lexicon&answers=extractive|count-3&captions=extractive|highlight-false\n200\nResults Found: 22433, Results Returned: 3\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1682294955909
        }
      },
      "id": "faf2e30f-e71f-4533-ab52-27d048b80a89"
    },
    {
      "cell_type": "code",
      "source": [
        "search_results\r\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "{'@odata.context': \"https://azure-cog-search-hw3sksxnht5m6.search.windows.net/indexes('cogsrch-index-csv')/$metadata#docs(*)\",\n '@odata.count': 22433,\n '@search.answers': [],\n 'value': [{'@search.score': 9.5399475,\n   '@search.rerankerScore': 1.0802764892578125,\n   '@search.captions': [{'text': 'Pandemics show us what government is for..',\n     'highlights': ''}],\n   'id': '32246104',\n   'title': 'Pandemics show us what government is for.',\n   'content': None,\n   'language': None,\n   'pages': [],\n   'journal': 'Nat Hum Behav',\n   'keywords': None,\n   'label': None,\n   'pub_type': 'Journal Article',\n   'authors': 'Erikson, Susan',\n   'date1': None,\n   'doi': '10.1038/s41562-020-0871-4',\n   'date2': '2020-04-05',\n   'label_category': 'title_abstract_title',\n   'metadata_storage_path': 'https://demodatasetsp.blob.core.windows.net/litcovid/train.csv'},\n  {'@search.score': 10.189932,\n   '@search.rerankerScore': 0.904266357421875,\n   '@search.captions': [{'text': 'Capitalism is groovy, but at what cost?. covid-19;diagnostic testing;public health. Due to the COVID-19 pandemic, the FDA was forced to bypass normal protocol and issue Emergency Use Authorization for diagnostic testing.',\n     'highlights': ''}],\n   'id': '33194126',\n   'title': 'Capitalism is groovy, but at what cost?',\n   'content': 'Due to the COVID-19 pandemic, the FDA was forced to bypass normal protocol and issue Emergency Use Authorization for diagnostic testing. As a result, we have seen an explosion in the number of available molecular diagnostic tests developed by various private enterprises. Our case reports of an 85-year-old female who was suffering from a multitude of co-morbidities and underwent three different molecular diagnostic tests in a short timeframe. With little data on the precision and reliability of the multiple available tests, it has become extremely difficult to diagnose and guide management. Instead of focusing on commercial ventures, FDA in conjunction with the CDC should prioritize our resources to tackle COVID-19 as a public health crisis.',\n   'language': 'en',\n   'pages': ['Due to the COVID-19 pandemic, the FDA was forced to bypass normal protocol and issue Emergency Use Authorization for diagnostic testing. As a result, we have seen an explosion in the number of available molecular diagnostic tests developed by various private enterprises. Our case reports of an 85-year-old female who was suffering from a multitude of co-morbidities and underwent three different molecular diagnostic tests in a short timeframe. With little data on the precision and reliability of the multiple available tests, it has become extremely difficult to diagnose and guide management. Instead of focusing on commercial ventures, FDA in conjunction with the CDC should prioritize our resources to tackle COVID-19 as a public health crisis.'],\n   'journal': 'J Community Hosp Intern Med Perspect',\n   'keywords': 'covid-19;diagnostic testing;public health',\n   'label': None,\n   'pub_type': 'Journal Article',\n   'authors': 'Vedala, Krishna;Sobash, Phillip T;Wang, Shiyu;Kamoga, Gilbert-Roy',\n   'date1': None,\n   'doi': '10.1080/20009666.2020.1803606',\n   'date2': '2020-11-17',\n   'label_category': 'difficult_manual',\n   'metadata_storage_path': 'https://demodatasetsp.blob.core.windows.net/litcovid/train.csv'},\n  {'@search.score': 8.7996435,\n   '@search.rerankerScore': 0.8607940673828125,\n   '@search.captions': [{'text': 'In this period, diseases other than coronavirus disease (COVID-19) have not disappeared; however, it is hard for doctors to diagnose diseases that can mimic the clinical, radiological, and laboratory features of COVID-19, especially rare lung diseases such as acute eosinophilic pneumonia (AEP).',\n     'highlights': ''}],\n   'id': '33173352',\n   'title': 'May 2020: Is It Always COVID-19 No Matter What?',\n   'content': 'Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is causing a massive outbreak throughout the world. In this period, diseases other than coronavirus disease (COVID-19) have not disappeared; however, it is hard for doctors to diagnose diseases that can mimic the clinical, radiological, and laboratory features of COVID-19, especially rare lung diseases such as acute eosinophilic pneumonia (AEP). We report the clinical case of a young patient who presented to the Emergency Department with respiratory failure and clinical symptoms, radiological aspects, and blood tests compatible with COVID-19; two swabs and a serology test for SARS-CoV-2 were performed, both resulted negative, but the respiratory failure worsened. Peripheral eosinophilia guided us to consider the possibility of a rare disease such as AEP, even if radiology findings were not pathognomonic. Therefore, we decided to perform a flexible bronchoscopy with bronchoalveolar lavage (BAL) at the lingula, which showed the presence of eosinophilia greater than 40%. As a consequence, we treated the patient with high-dose corticosteroids that completely resolved the respiratory symptoms. This case report highlights the difficulty of making alternative diagnoses during the COVID-19 pandemic, especially for rare lung diseases such as AEP, which may have initial characteristics similar to COVID-19.',\n   'language': 'en',\n   'pages': ['Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is causing a massive outbreak throughout the world. In this period, diseases other than coronavirus disease (COVID-19) have not disappeared; however, it is hard for doctors to diagnose diseases that can mimic the clinical, radiological, and laboratory features of COVID-19, especially rare lung diseases such as acute eosinophilic pneumonia (AEP). We report the clinical case of a young patient who presented to the Emergency Department with respiratory failure and clinical symptoms, radiological aspects, and blood tests compatible with COVID-19; two swabs and a serology test for SARS-CoV-2 were performed, both resulted negative, but the respiratory failure worsened. Peripheral eosinophilia guided us to consider the possibility of a rare disease such as AEP, even if radiology findings were not pathognomonic. Therefore, we decided to perform a flexible bronchoscopy with bronchoalveolar lavage (BAL) at the lingula, which showed the presence of eosinophilia greater than 40%. As a consequence, we treated the patient with high-dose corticosteroids that completely resolved the respiratory symptoms. This case report highlights the difficulty of making alternative diagnoses during the COVID-19 pandemic, especially for rare lung diseases such as AEP, which may have initial characteristics similar to COVID-19.'],\n   'journal': 'Int Med Case Rep J',\n   'keywords': 'covid-19;acute eosinophilic pneumonia;bronchoalveolar lavage;ground glass opacities',\n   'label': 'Case Report',\n   'pub_type': 'Case Reports',\n   'authors': 'Livrieri, Francesco;Ghidoni, Giulia;Piro, Roberto;Menzella, Francesco;Cavazza, Alberto;Lazzaretti, Claudia;Massari, Marco;Montanari, Gloria;Fontana, Matteo;Facciolongo, Nicola Cosimo',\n   'date1': None,\n   'doi': '10.2147/IMCRJ.S277474',\n   'date2': '2020-11-12',\n   'label_category': 'difficult_weak',\n   'metadata_storage_path': 'https://demodatasetsp.blob.core.windows.net/litcovid/train.csv'}]}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1682294959762
        }
      },
      "id": "4420fff7-46f5-49be-b629-0610c94b4d79"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display the top results (from both searches) based on the score"
      ],
      "metadata": {
        "tags": []
      },
      "id": "b7fd0fe5-4ee0-42e2-a920-72b93a407389"
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML('<h4>Top Answers</h4>'))\n",
        "\n",
        "for search_results in agg_search_results:\n",
        "    for result in search_results['@search.answers']:\n",
        "        if result['score'] > 0.5: # Show answers that are at least 50% of the max possible score=1\n",
        "            display(HTML('<h5>' + 'Answer - score: ' + str(result['score']) + '</h5>'))\n",
        "            display(HTML(result['text']))\n",
        "            \n",
        "print(\"\\n\\n\")\n",
        "display(HTML('<h4>Top Results</h4>'))\n",
        "\n",
        "file_content = OrderedDict()\n",
        "content = dict()\n",
        "\n",
        "for search_results in agg_search_results:\n",
        "    for result in search_results['value']:\n",
        "        if result['@search.rerankerScore'] > 1: # Filter results that are at least 25% of the max possible score=4\n",
        "            content[result['id']]={\n",
        "                                    \"title\": result['title'],\n",
        "                                    \"chunks\": result['pages'],\n",
        "                                    \"language\": result['language'], \n",
        "                                    \"caption\": result['@search.captions'][0]['text'],\n",
        "                                    \"score\": result['@search.rerankerScore'],\n",
        "                                    \"location\": result['metadata_storage_path']                  \n",
        "                                }\n",
        "    \n",
        "    #After results have been filtered we will Sort and add them as an Ordered list\\n\",\n",
        "    for id in sorted(content, key= lambda x: content[x][\"score\"], reverse=True):\n",
        "        file_content[id] = content[id]\n",
        "        display(HTML('<h5>' + str(file_content[id]['title']) + '&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: '+ str(file_content[id]['score']) + '</h5>'))\n",
        "        display(HTML(file_content[id]['caption']))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h4>Top Answers</h4>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5>Answer - score: 0.80517578125</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "CDP Controls – Working remotely guidelines Working From the Road - e.g. client site, airport, airplane, train, hotel, restaurant, etc.  Dos Don’ts Keep your business to yourself. Be aware of your surroundings. If you must view sensitive   Avanade or client information in public, be sure to use a privacy screen."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n\n\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h4>Top Results</h4>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5>2019 Form 1040-SR&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 1.8394775390625</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Declaration of preparer (other than taxpayer) is based on all information  of which preparer has any knowledge. Your signature Date Your occupation If the IRS sent you an Identity  Protection PIN, enter it here   (see inst.)  Spouse’s signature."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5>None&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 1.7364501953125</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Declaration of preparer (other than taxpayer) is based on all information of which preparer has any knowledge. Your signature Date Your occupation If the IRS sent you an Identity  Protection PIN, enter it here   (see inst.)  Spouse’s signature. If a joint return, both must sign."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5>PowerPoint Presentation&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 1.019500732421875</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "CDP Controls – Working remotely guidelines Working From the Road - e.g. client site, airport, airplane, train, hotel, restaurant, etc.  Dos Don’ts Keep your business to yourself. Be aware of your surroundings. If you must view sensitive   Avanade or client information in public, be sure to use a privacy screen."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5>2019 Form 1040-SR&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 1.8394775390625</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Declaration of preparer (other than taxpayer) is based on all information  of which preparer has any knowledge. Your signature Date Your occupation If the IRS sent you an Identity  Protection PIN, enter it here   (see inst.)  Spouse’s signature."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5>None&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 1.7364501953125</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Declaration of preparer (other than taxpayer) is based on all information of which preparer has any knowledge. Your signature Date Your occupation If the IRS sent you an Identity  Protection PIN, enter it here   (see inst.)  Spouse’s signature. If a joint return, both must sign."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5>Pandemics show us what government is for.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 1.0802764892578125</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Pandemics show us what government is for.."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5>PowerPoint Presentation&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 1.019500732421875</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "CDP Controls – Working remotely guidelines Working From the Road - e.g. client site, airport, airplane, train, hotel, restaurant, etc.  Dos Don’ts Keep your business to yourself. Be aware of your surroundings. If you must view sensitive   Avanade or client information in public, be sure to use a privacy screen."
          },
          "metadata": {}
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1682295036868
        }
      },
      "id": "9e938337-602d-4b61-8141-b8c92a5d91da"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comments on Query results"
      ],
      "metadata": {},
      "id": "52a6d3e6-afb2-4fa7-96d3-69bc2373ded5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "As seen above the semantic search feature of Azure Cognitive Search service is good. It gives us some answers and also the top results with the corresponding file and the paragraph where the answers is possible located.\n",
        "\n",
        "Let's see if we can make this better with Azure OpenAI"
      ],
      "metadata": {},
      "id": "84e02227-6a92-4944-86f8-6c1e38d90fe4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Azure OpenAI\n",
        "\n",
        "Of course we want OpenAI to give a better answer, so we instead of sending these results, <u>_we send the content of the documents of the search result articles to OpenAI and lets GPT model give the answer._</u>\n",
        "In MIKES case, he had reduced the Top 10 to Top 3, so, only had three (3) results returned to select from....\n",
        "The problem is that the content of the search result files is or can be very lengthy, more than the allowed tokens allowed by the GPT Azure OpenAI models. So what we need to do is to split in chunks, vectorize and do a vector semantic search. \n",
        "\n",
        "Notice that **the documents chunks are already done in Azure Search**. file_content dictionary (created in the cell above) contains the pages (chunks) of each document. So we dont really need to chunk them again, each doc page for sure will fit on the max tokens limit of the completions LLM and of the embedding LLM.\n",
        "\n",
        "We will use a genius library call LangChain that wraps a lot of boiler plate code."
      ],
      "metadata": {},
      "id": "8df3e6d4-9a09-4b0f-b328-238738ccfaec"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "# NOTE the below clever Python with two ='s     if a = b if b exists, else a = c....  go look it up...\n",
        "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_OPENAI_ENDPOINT\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_API_KEY\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"] = AZURE_OPENAI_API_VERSION"
      ],
      "outputs": [],
      "execution_count": 36,
      "metadata": {
        "gather": {
          "logged": 1682295748771
        }
      },
      "id": "eea62a7d-7e0e-4a93-a89c-20c96560c665"
    },
    {
      "cell_type": "code",
      "source": [
        "docs = []\n",
        "for key,value in file_content.items():\n",
        "    for page in value[\"chunks\"]:\n",
        "        docs.append(Document(page_content=page, metadata={\"source\": value[\"location\"]}))\n",
        "        \n",
        "print(\"Number of chunks:\",len(docs))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Number of chunks: 16\n"
        }
      ],
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1682295751186
        }
      },
      "id": "8f7b41d2-65b0-4058-8a46-c76cf6960720"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depending of the amount of chunks/pages returned from the search result, which is very related to the size of the documents returned\n",
        "we pick the embedding model that give us fast results. <br>The logic is, if there is less than 50 chunks (of 5000 chars each) to vectorize then we use \n",
        "OpenAI models which currently don't offer batch processing, but if there is more than 50 chunks we use a BERT based in-memory model that processes in batches and in parallel (it is recommended a VM of at least 4 cores).\n",
        "\n",
        "For more information on in-memory models that you can use, see [HERE](https://www.sbert.net/docs/pretrained_models.html)"
      ],
      "metadata": {},
      "id": "c5403dee-a4c4-420c-9819-68151d973695"
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the Embedder model\n",
        "if len(docs) < 50:\n",
        "    # OpenAI models are accurate but slower\n",
        "    embedder = OpenAIEmbeddings(document_model_name=\"text-embedding-ada-002\", query_model_name=\"text-embedding-ada-002\") \n",
        "else:\n",
        "    # Bert based models are faster (3x-10x) but not as great in accuracy as OpenAI models\n",
        "    # Since this repo supports Multiple languages we need to use a multilingual model. \n",
        "    # But if English only is the requirement, use \"multi-qa-MiniLM-L6-cos-v1\"\n",
        "    # The fastest english model is \"all-MiniLM-L12-v2\"\n",
        "    if random.choice(list(file_content.items()))[1][\"language\"] == \"en\":\n",
        "        embedder = HuggingFaceEmbeddings(model_name = 'multi-qa-MiniLM-L6-cos-v1')\n",
        "    else:\n",
        "        embedder = HuggingFaceEmbeddings(model_name = 'distiluse-base-multilingual-cased-v2')"
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1682295755105
        }
      },
      "id": "a03f1f10-32b0-4c1e-8a0e-eee1b1d29ce7"
    },
    {
      "cell_type": "code",
      "source": [
        "embedder"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 39,
          "data": {
            "text/plain": "OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, document_model_name='text-embedding-ada-002', query_model_name='text-embedding-ada-002', openai_api_key=None)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1682295757679
        }
      },
      "id": "a5cc7ae5-6fe9-4fd8-992d-0507297387ea"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "if(len(docs)>1):\n",
        "    db = FAISS.from_documents(docs, embedder)\n",
        "else:\n",
        "    print(\"No results Found\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 90.5 ms, sys: 17.9 ms, total: 108 ms\nWall time: 1.64 s\n"
        }
      ],
      "execution_count": 40,
      "metadata": {},
      "id": "3315033a-4a08-4db5-8f5c-fa0a99892dc4"
    },
    {
      "cell_type": "code",
      "source": [
        "docs_db = db.similarity_search(QUESTION, k=4)"
      ],
      "outputs": [],
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1682295772169
        }
      },
      "id": "57429335-34d3-458a-b7c9-52482a0936d5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point we already have the most similar chunks (in order of relevance given by the in-memory vector cosine similarity search) in docs_db"
      ],
      "metadata": {},
      "id": "17247488-7d14-4178-9add-31eb1afcbcbe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now we use GPT-3.5(Turbo) using map-reduce chain in order to stay within the limits of the allow model's token count\n",
        "\n",
        "for more information on the different types of prompts for these chains please see here:\n",
        "\n",
        "https://github.com/hwchase17/langchain/tree/master/langchain/chains/question_answering"
      ],
      "metadata": {},
      "id": "793c4788-715e-44dd-b2b8-3f1c3201e4e0"
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure you have the deployment named \"gpt-35-turbo\" for the model \"gpt-35-turbo (0301)\". \n",
        "# Use \"gpt-4\" if you have it available.\n",
        "llm = AzureChatOpenAI(deployment_name=\"gpt-35-turbo\", temperature=0.9, max_tokens=500)\n",
        "chain = load_qa_with_sources_chain(llm, chain_type=\"map_reduce\", return_intermediate_steps=True)"
      ],
      "outputs": [],
      "execution_count": 42,
      "metadata": {
        "gather": {
          "logged": 1682295783900
        }
      },
      "id": "634f5bd8-0d56-47b8-84fd-fe9b678bfc32"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "response = chain({\"input_documents\": docs_db, \"question\": QUESTION}, return_only_outputs=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 280 ms, sys: 73.1 ms, total: 354 ms\nWall time: 15 s\n"
        }
      ],
      "execution_count": 43,
      "metadata": {},
      "id": "a1e619b8-1dcf-431b-8aad-f1696a09c2ac"
    },
    {
      "cell_type": "code",
      "source": [
        "# 2023Apr20 replaced with better if else test from mev... avoid 'Invalid Index error..'\n",
        "# answer = response['output_text']\n",
        "\n",
        "# display(HTML('<h4>Azure OpenAI ChatGPT Answer:</h4>'))\n",
        "# print(answer.split(\"SOURCES:\")[0])\n",
        "# print(\"Sources:\")\n",
        "# print(answer.split(\"SOURCES:\")[1].replace(\" \",\"\").split(\",\"))"
      ],
      "outputs": [],
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1682295805669
        }
      },
      "id": "8cddb1cb-a4a0-4e2f-9f0c-4216b0f232b2"
    },
    {
      "cell_type": "code",
      "source": [
        "answer = response['output_text']\r\n",
        "\r\n",
        "display(HTML('<h4>Azure OpenAI ChatGPT Answer:</h4>'))\r\n",
        "print(answer.split(\"SOURCES:\")[0])\r\n",
        "#20230419 Mark Vogt (Avanade) ADDED exception-handling in case \"answer\" comes back with NO \"SOURCES:\"...\r\n",
        "if(answer.find(\"SOURCES:\") < 0):\r\n",
        "    print(\"Sources: none\")\r\n",
        "else:\r\n",
        "    print(\"Sources:\")\r\n",
        "    print(answer.split(\"SOURCES:\")[1].replace(\" \",\"\").split(\",\"))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h4>Azure OpenAI ChatGPT Answer:</h4>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CDP stands for Client Data Protection, and it is a plan that governs the protection of client information and systems entrusted to Avanade. CDP Owners are responsible for developing and maintaining the plan, while CDP Participants are responsible for delivering contracted services securely by following CDP control requirements and reporting incidents promptly. The plan includes various controls and guidelines for data management and privacy to mitigate risks in compliance with GDPR. \n\nSources:\n['https://asaforaoaisandbox01.blob.core.windows.net/container-openai-sandbox-01/CDP%20-%20Training_General_Controls.pdf']\n"
        }
      ],
      "execution_count": 45,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1682295805808
        }
      },
      "id": "ce48c840-8ae2-4278-86ae-e21d00a7df9d"
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment if you want to inspect the results from each top similar chunk (k=4 by default)\n",
        "response['intermediate_steps']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "11345374-6420-4b36-b061-795d2a804c85"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "##### This answer is way better than taking just the result from Azure Cognitive Search. So the summary is:\n",
        "- Azure Cognitive Search give us the top results (context)\n",
        "- Azure OpenAI takes these results and understand the content and uses it as context to give the best answer\n",
        "- Best of two worlds!"
      ],
      "metadata": {},
      "id": "f347373a-a5be-473d-b64e-0f6b6dbcd0e0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NEXT\n",
        "We know now how to do a Smart Search Engine!! great!\n",
        "\n",
        "But, does this solve all the possible scenarios that a virtual assistant will require?  **What about if the answer to the Smart Search Engine is not related to text, but instead requires to look into tabular data?** The next notebook 04 explains and solves this problem"
      ],
      "metadata": {},
      "id": "fdc6e2fe-1c34-4952-99ad-14940f022379"
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}